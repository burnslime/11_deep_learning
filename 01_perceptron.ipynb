{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 인공신경망 Artificial Neural Network\n",
    "\n",
    "\n",
    "![](https://d.pr/i/P9blGn+)\n",
    "\n",
    "\n",
    "1. **매컬리-피츠 뉴런(McCulloch-Pitts Neuron)**\n",
    "\n",
    "\n",
    "    1943년, 신경과학자 워런 매컬리(Warren McCulloch)와 논리학자 월터 피츠(Walter Pitts)는 뉴런을 수학적으로 모델링하여 단순 논리 연산을 수행할 수 있게 했다.\n",
    "\n",
    "\n",
    "    이 모델은 뉴런이 \"발화\"하거나 \"비발화\"하는 이진 결정 방식으로 동작했고, 학습 능력에는 한계가 있었다. 현재 인공신경망의 노드 개념의 기초가 되었다.\n",
    "\n",
    "\n",
    "2. **단층 퍼셉트론(Single-layer Perceptron)**\n",
    "\n",
    "\n",
    "    로젠블랫의 퍼셉트론은 매컬리-피츠 뉴런을 확장하여 가중치를 통해 데이터를 학습할 수 있게 했고, 선형 분류 문제(예: OR 또는 AND 문제)에서는 성공적인 성능을 보였다.\n",
    "\n",
    "\n",
    "    그러나 XOR 문제와 같은 비선형 문제를 해결하지 못한다는 한계가 있었다.\n",
    "\n",
    "\n",
    "    이러한 단점으로 인해 인공신경망 연구는 1970년대에 한동안 침체기에 들어갔는데, 이를 **첫번째 AI 겨울(AI Winter)** 이라 부른다.\n",
    "\n",
    "\n",
    "3. **다층 퍼셉트론(Multilayer Perceptron, MLP)**\n",
    "\n",
    "\n",
    "    1980년대, 입력층과 출력층 사이에 **은닉층(hidden layer)**을 추가하여 비선형 문제도 해결할 수 있는 구조의 MLP가 등장해 다시 주목받기 시작한다.\n",
    "\n",
    "\n",
    "    은닉층을 여러 개 쌓은 MLP는 오차 역전파(Backpropagation) 알고리즘을 통해 각 층의 가중치를 조정하며 학습할 수 있다.\n",
    "\n",
    "\n",
    "    이 방법은 제프리 힌튼(Geoffrey Hinton)과 데이비드 럼멜하트(David Rumelhart)에 의해 개발되었으며, MLP의 성능을 비약적으로 향상시켰다.\n",
    "\n",
    "\n",
    "4. **심층 신경망(Deep Neural Network)**\n",
    "\n",
    "\n",
    "    다층 퍼셉트론의 등장 이후 인공신경망 연구는 빠르게 발전하여 오늘날의 심층 신경망(Deep Neural Network) 개념으로 이어졌다.\n",
    "\n",
    "\n",
    "    이처럼 매컬리-피츠 뉴런에서 시작된 인공신경망 연구는 퍼셉트론을 거쳐 다층 퍼셉트론으로 발전했으며, 현대의 다양한 인공지능 응용 분야에 널리 활용되고 있다.\n"
   ],
   "id": "9eed94a88eb06eb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Perceptron\n",
    "\n",
    "퍼셉트론(Perceptron)은 인공지능과 머신러닝의 기본 모델 중 하나로, 인공 신경망의 가장 기본 단위이다.\n",
    "\n",
    "1958년 프랭크 로젠블랫(Frank Rosenblatt)에 의해 개발되었으며, 주로 이진 분류 문제를 해결하는 데 사용한다.\n",
    "\n",
    "**퍼셉트론의 구성 요소**\n",
    "1. **입력 노드(Input Nodes)**: 퍼셉트론은 여러 개의 입력을 받으며, 각 입력은 특징 벡터의 한 요소에 해당한다.\n",
    "2. **가중치(Weights)**: 각 입력에는 가중치가 부여된다. 가중치는 학습 과정에서 조정되며, 입력이 결과에 미치는 영향을 조절하는 역할을 한다.\n",
    "3. **편향(Bias)**: 퍼셉트론의 활성화 함수를 조절하는 상수 값이다. 입력 데이터의 선형 조합이 특정 값 이상이 되도록 하는 역할을 한다.\n",
    "4. **활성화 함수(Activation Function)**: 입력 값과 가중치의 선형 결합 결과를 이진 출력으로 변환한다. 퍼셉트론에서는 보통 단위 계단 함수를 사용한다.\n",
    "\n",
    "**퍼셉트론의 작동 원리**\n",
    "\n",
    "1. **입력 신호와 가중치의 합산:**\n",
    "\n",
    "   $\n",
    "   z = \\sum_{i=1}^{n} w_i x_i + b\n",
    "   $\n",
    "\n",
    "   여기서:\n",
    "   - $ x_i $는 $ i $번째 입력 값,\n",
    "   - $ w_i $는 $ i $번째 가중치,\n",
    "   - $ b $는 편향(bias) 값,\n",
    "   - $ z $는 가중치가 적용된 입력 신호의 총합이다.\n",
    "\n",
    "2. **활성화 함수 적용:**\n",
    "\n",
    "   $\n",
    "   y = \\begin{cases}\n",
    "      1, & \\text{if } z \\geq 0 \\\\\n",
    "      0, & \\text{if } z < 0\n",
    "   \\end{cases}\n",
    "   $\n",
    "\n",
    "   여기서:\n",
    "   - $ y $는 퍼셉트론의 출력 값으로, 활성화 함수에 의해 결정된다.\n",
    "   - 활성화 함수는 대표적으로 **계단 함수**(step function)로, 총합 $ z $가 0 이상일 때 1을, 그렇지 않으면 0을 출력한다.\n",
    "\n",
    "    ![](https://d.pr/i/lt1GXE+)\n",
    "\n",
    "이 수식을 통해 퍼셉트론은 입력을 받아 단순한 이진 분류를 수행한다.\n",
    "\n",
    "**퍼셉트론의 한계**\n",
    "\n",
    "퍼셉트론은 단층 구조로 구성되어 있기 때문에 선형 분리가 가능한 문제만 해결할 수 있다.\n",
    "\n",
    "XOR 문제와 같이 선형 분리가 불가능한 문제는 단일 퍼셉트론으로 해결할 수 없다.\n",
    "\n",
    "이러한 한계를 이유로 AI의 첫번째 겨울을 맞이하였으며, 이후 1980년대에 오차역전파와 다층 퍼셉트론(MLP: Multi-Layer Perceptron)에 의해 이 한계가 극복되었다.\n",
    "\n",
    "**선형 분리**\n",
    "![](https://d.pr/i/uLz908+)\n",
    "\n",
    "**논리 게이트(Logical Gates)**\n",
    "1. AND (논리곱)\n",
    "    - **정의**: 두 입력이 모두 1일 때만 1을 출력하고, 나머지 경우에는 0을 출력.\n",
    "    - **진리표**:\n",
    "\n",
    "      | 입력 A | 입력 B | AND |\n",
    "      |--------|--------|-----|\n",
    "      | 0      | 0      | 0   |\n",
    "      | 0      | 1      | 0   |\n",
    "      | 1      | 0      | 0   |\n",
    "      | 1      | 1      | 1   |\n",
    "\n",
    "2. OR (논리합)\n",
    "    - **정의**: 두 입력 중 하나라도 1이면 1을 출력하고, 둘 다 0일 때만 0을 출력.\n",
    "    - **진리표**:\n",
    "\n",
    "      | 입력 A | 입력 B | OR  |\n",
    "      |--------|--------|-----|\n",
    "      | 0      | 0      | 0   |\n",
    "      | 0      | 1      | 1   |\n",
    "      | 1      | 0      | 1   |\n",
    "      | 1      | 1      | 1   |\n",
    "\n",
    "3. XOR (배타적 논리합)\n",
    "    - **정의**: 두 입력이 다를 때만 1을 출력하고, 같을 때는 0을 출력.\n",
    "    - **진리표**:\n",
    "\n",
    "      | 입력 A | 입력 B | XOR |\n",
    "      |--------|--------|-----|\n",
    "      | 0      | 0      | 0   |\n",
    "      | 0      | 1      | 1   |\n",
    "      | 1      | 0      | 1   |\n",
    "      | 1      | 1      | 0   |\n",
    "\n",
    "4. NAND (부정 논리곱)\n",
    "    - **정의**: AND의 결과를 뒤집어, 두 입력이 모두 1일 때만 0을 출력하고, 나머지 경우에는 1을 출력.\n",
    "    - **진리표**:\n",
    "\n",
    "      | 입력 A | 입력 B | NAND |\n",
    "      |--------|--------|------|\n",
    "      | 0      | 0      | 1    |\n",
    "      | 0      | 1      | 1    |\n",
    "      | 1      | 0      | 1    |\n",
    "      | 1      | 1      | 0    |\n"
   ],
   "id": "15b75822fa18438f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 단층 퍼셉트론",
   "id": "c8b49becf507b19d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "7abdfcc8ecfa76ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "\n",
    "    def activation_function(self, z):\n",
    "        \"\"\" 계단 함수 \"\"\"\n",
    "        # print('z = ', z)\n",
    "        return 1 if z > 0 else 0\n",
    "\n",
    "    def __call__(self, X):\n",
    "        \"\"\" 현재 객체를 함수처럼 호출하는 함수 \"\"\"\n",
    "        # print(X)\n",
    "        return self.activation_function(np.dot(self.W, X) + self.b)\n",
    "\n",
    "# and_gate : 0 0 0 1\n",
    "# or_gate  : 0 1 1 1\n",
    "test_input = [(0, 0), (0, 1), (1, 0), (1, 1)]"
   ],
   "id": "5b84261d0ce92160",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# and_gate\n",
    "\n",
    "and_gate = Perceptron(W=[0.5, 0.5], b=-0.7)\n",
    "# and_gate((0,0))\n",
    "\n",
    "for input in test_input:\n",
    "    print(input, ' -> ', and_gate(input))\n"
   ],
   "id": "b54d9ac476a480d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# or_gate\n",
    "or_gate = Perceptron(W=[0.5, 0.5], b=-0.1)\n",
    "for input in test_input:\n",
    "    print(input, ' -> ', or_gate(input))"
   ],
   "id": "9391e013d334222c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# nand_gate 1 1 1 0\n",
    "nand_gate = Perceptron(W=[-0.5, -0.5], b= 1)\n",
    "for input in test_input:\n",
    "    print(input, ' -> ', nand_gate(input))"
   ],
   "id": "23d4d6fc1adca982",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# xor_gate 0 1 1 0\n",
    "# 첫번째 AI의 겨울 - 단층퍼셉트론으로는 XOR 문제를 해결할 수 없다\n",
    "xor_gate = Perceptron(W=[-0.5, -0.5], b= 1)\n",
    "for input in test_input:\n",
    "    print(input, ' -> ', xor_gate(input))"
   ],
   "id": "97942da638fb04e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "gates = {\n",
    "    'AND': and_gate,\n",
    "    'OR': or_gate,\n",
    "    'NAND': nand_gate,\n",
    "    'XOR': xor_gate\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "for i, (gate_name, perceptron) in enumerate(gates.items()):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # x축 y축 제한\n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "\n",
    "    # tick 단순화\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "\n",
    "    ax.set_title(f'{gate_name} Gate')\n",
    "\n",
    "    # XOR는 결정경계선을 작성할 수 없다\n",
    "    if gate_name == 'XOR':\n",
    "        ax.scatter(\n",
    "            [0, 0, 1, 1], [0, 1, 0, 1],\n",
    "            c=['blue', 'red', 'red', 'blue'],\n",
    "            s=100,\n",
    "            edgecolors='k'\n",
    "        )\n",
    "        continue\n",
    "\n",
    "\n",
    "    outputs = [perceptron(X) for X in inputs]\n",
    "\n",
    "    # print(outputs)\n",
    "    ''' =>\n",
    "    [0, 0, 0, 1]\n",
    "    [0, 1, 1, 1]\n",
    "    [1, 1, 1, 0]\n",
    "    [1, 1, 1, 0]\n",
    "    '''\n",
    "\n",
    "    for (x1, x2), y in zip(inputs, outputs):\n",
    "        ax.scatter(\n",
    "            x1, x2,\n",
    "            c='red' if y==1 else 'blue', # ==> y가 1일때는 빨강, 아니면 파랑\n",
    "            s=100, # ==> 사이즈를 100으로\n",
    "            edgecolors='k', # ==> 테두리 색 검정\n",
    "        )\n",
    "\n",
    "    # 결정경계 - 최종출력이 0인지 1인지 결정하는 경계선\n",
    "    # z = W * X + b = (w1 * x1) + (w2 * x2) + b\n",
    "    # z = 0 -> (w1 * x1) + (w2 * x2) + b = 0\n",
    "    # x2 = -(w1 * x1 - b) / w2\n",
    "    x_vals = np.linspace(-0.1, 1.1, 100)\n",
    "    y_vals = (-perceptron.W[0] * x_vals - perceptron.b) / perceptron.W[1]\n",
    "    ax.plot(x_vals, y_vals, 'k--')\n",
    "\n"
   ],
   "id": "a42636fe39d8f23c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 다층 퍼셉트론(Multi-Layer Perceptron, MLP)\n",
    "단층 퍼셉트론의 한계를 극복하기 위해 여러 개의 퍼셉트론을 쌓아올린 형태\n",
    "\n",
    "\n",
    "![](https://d.pr/i/Cea59r+)"
   ],
   "id": "a46051f68ea61483"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MLP:\n",
    "    \"\"\" Multi-layer Perceptron \"\"\"\n",
    "\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "    def activation_function(self, z):\n",
    "        return np.where(z > 0, 1, 0) # where(조건식, true, false)\n",
    "        # ==> 삼항연산자랑 비슷함\n",
    "\n",
    "    def __call__(self, X):\n",
    "        for W, b in zip(self.W, self.b):\n",
    "            print(f'\\nW{W.shape}={W}')\n",
    "            print(f'X{X.shape}={X}')\n",
    "            print(f'b{b.shape}={b}')\n",
    "            X = np.dot(W, X) + b\n",
    "            X = self.activation_function(X)\n",
    "            print(f'z{X.shape}={X}')\n",
    "        return X"
   ],
   "id": "c4cb45a5a1fdcf7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# XOR 해결을 위한 가중치/절편 준비\n",
    "# 입력층(2개) -> 은닉층(2개) -> 출력층(1개)\n",
    "\n",
    "# 은닉층 : 2개 노드(또는 2개 뉴런 이라고도 함)\n",
    "hidden_W = np.array([[1.0, 1.0],\n",
    "                     [-1.0, -1.0]])\n",
    "hidden_b = np.array([-0.5, 1.5])\n",
    "\n",
    "# 출력층 : 1개 노드(뉴런)\n",
    "output_W = np.array([[1.0, 1.0]])\n",
    "output_b = np.array([-1.0])\n",
    "\n",
    "# 가중치/절편 처리\n",
    "for i, (W, b) in enumerate(zip([hidden_W,output_W], [hidden_b,output_b])):\n",
    "    print(f'{i} : \\nW={W}, b={b}')"
   ],
   "id": "bb2d75ce0cfa8b41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xor_gate = MLP(W=[hidden_W, output_W], b=[hidden_b, output_b])\n",
    "\n",
    "inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "\n",
    "for X in inputs :\n",
    "    X = np.array(X)\n",
    "    y = xor_gate(X)\n",
    "    print('='*5, X.tolist(), '->', y, '='*5)"
   ],
   "id": "304d97fd673bf5da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## pytorch 환경설정\n",
    "https://pytorch.org/get-started/locally/"
   ],
   "id": "254cf307a5097bd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#%pip install torch torchvision torchaudio\n",
    "%pip install torch torchvision\n",
    "# ==> CPU 버전\n",
    "# ==> 이거 먼저 하고 다시 아래 시도?\n",
    "\n",
    "# ==> GPU 버전인데 너무 오래 걸림\n",
    "#%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126"
   ],
   "id": "a05eae0d9ffec5be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T06:20:00.398991Z",
     "start_time": "2025-12-29T03:24:56.017666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print('torch : ', torch.__version__)\n",
    "# print('cuda available : ', torch.cuda.is_available())"
   ],
   "id": "65d00c2a9c6bf328",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ],
   "id": "782cc317dc67aa7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## torch 모델 학습 생명주기",
   "id": "e52eef0f5092d17e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tensor\n",
    "\n",
    "\n",
    "- 차원의 개수와 상관없이 숫자를 담을 수 있는 일반화된 자료 구조\n",
    "(스칼라, 벡터, 행렬을 모두 포함)\n",
    "\n",
    "\n",
    "**특징**\n",
    "\n",
    "\n",
    "- 값을 가지고 있음\n",
    "\n",
    "\n",
    "- 연산을 통해 만들어진 경우, 해당 연산 정보를 연산 그래프 형태로 참조함\n",
    "\n",
    "\n",
    "- requires_grad=True인 경우, 미분 결과를 저장할 수 있음\n"
   ],
   "id": "e80dcd8b1d7caa20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.nn as nn # Neural Network(신경망)\n",
    "import torch.optim as optim\n",
    "\n",
    "# 데이터 준비\n",
    "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = torch.tensor([[0], [1], [1], [0]])\n",
    "\n",
    "print(X, type(X))\n",
    "print(y, type(y))"
   ],
   "id": "eddd21286b3f0997"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 모델 생성\n",
    "# - nn.Module 상속\n",
    "# ==> 매우 중요\n",
    "\n",
    "class XORNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(2, 4) # 입력속성개수 2 , 출력속성개수 4\n",
    "        # ==> 아까는 2개 들어가서 2개가 나왔지만 이번에는 4개\n",
    "        # ==> 모든 경우의 수를 계산하는건 이전이나 지금이나 똑같다\n",
    "\n",
    "        self.output = nn.Linear(4, 1) # 입력속성개수 4 , 출력속성개수 1\n",
    "        self.relu = nn.ReLU() # 은닉층 활성화함수\n",
    "        self.sigmoid = nn.Sigmoid()  # 출력층 활성화함수\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x) # ==> 은닉층 먼저 통과\n",
    "        x = self.relu(x) # ==> 은닉층에서 나온걸 활성화함수에 넣기\n",
    "        x = self.output(x)  # ==> 출력층\n",
    "        x = self.sigmoid(x) # ==> 출력층 활성화함수\n",
    "        return x\n",
    "\n",
    "\n",
    "# 모델/손실함수/최적화함수 선언\n",
    "model = XORNet()\n",
    "# ==> Net이 붙은 이유 : 모델 자체를 하나의 Net으로 취급?\n",
    "criterion = nn.BCELoss() # 이진분류용 손실함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) # 최적화 함수\n",
    "# ==> optimizer는 가중치 업데이트를 담당\n",
    "\n",
    "model\n",
    "''' =>\n",
    "XORNet(\n",
    "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
    "  (output): Linear(in_features=4, out_features=1, bias=True)\n",
    "  (relu): ReLU()\n",
    "  (sigmoid): Sigmoid()\n",
    ")\n",
    "'''\n"
   ],
   "id": "b42df539eb7b9886"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# %pip install torchinfo -q",
   "id": "1246aac499040732"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torchinfo import summary\n",
    "# summary(model)\n",
    "summary(model, input_size=(1, 2))"
   ],
   "id": "40f26ac57b08ced6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
